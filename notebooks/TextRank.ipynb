{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lA48wNvME4Em"
   },
   "source": [
    "# GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j2wDQssHPtw4",
    "outputId": "bbff1438-ec90-4fc2-bda1-7a22376fceef"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "onycWqyiP8Od",
    "outputId": "f6155f09-eb4f-446c-b7f5-a7e6ceaaf830"
   },
   "outputs": [],
   "source": [
    "# memory footprint support libraries/code\n",
    "\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "\n",
    "printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjVFhaIMgmwE"
   },
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOngHFvfEmCO"
   },
   "source": [
    "# Data Warehousing Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UfHxbgwP4oEp",
    "outputId": "f50154c4-1c13-4437-d8e0-99fc2ad8adb9"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oCY70XRU3f41",
    "outputId": "54f33622-c405-4e56-8fed-fd81d9783976"
   },
   "outputs": [],
   "source": [
    "# Add models repos and dave space\n",
    "\n",
    "%cd  /content/drive/My Drive/Models Running/Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDDYUhuCEbbZ"
   },
   "source": [
    "# Text Rank Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FRNSXAXW9K38",
    "outputId": "c22628ac-8b0f-42e7-fb1d-f2f2ed2844c4"
   },
   "outputs": [],
   "source": [
    "! pip install networkx==1.11\n",
    "! pip install graphviz==0.7.1\n",
    "! pip install -U spacy==1.10.1\n",
    "#! pip install statistics==1.0.3.5\n",
    "! pip install datasketch==1.2.1 -U\n",
    "#! pip install matplotlib==2.1 # Include if graph needs to be produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWHxe6bT9KBE"
   },
   "outputs": [],
   "source": [
    "#! rm -rf pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "vOWh2e6Bhqwd",
    "outputId": "8b123eba-ef39-433f-8ab2-86675fdb02ff"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/DerwenAI/pytextrank.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "s3z9U59HJ1Si",
    "outputId": "604b586c-0322-43f7-bd59-8667e9c45fb2"
   },
   "outputs": [],
   "source": [
    "! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D0o0WOk_JIb5",
    "outputId": "c7679416-ab2e-43f5-da1f-cfb3d22c0346"
   },
   "outputs": [],
   "source": [
    "% cd /content/drive/My Drive/Models Running/Summarization/pytextrank/pytextrank\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "import pylab as plt\n",
    "\n",
    "import pytextrank as ptr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "genre = pd.read_csv('/content/drive/My Drive/Models Running/Summarization/datasets/genre_final_for_summarization.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrnCm1ZFvTRd"
   },
   "outputs": [],
   "source": [
    "genre.drop(columns=['song', 'artist', 'genre', 'lyrics_nchar'], inplace=True)\n",
    "genre.set_index('genre_encoded', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0zEdRkzugK4"
   },
   "outputs": [],
   "source": [
    "def create_summary(line):\n",
    "    \n",
    "  # Convert Dataframe's row into dictionary\n",
    "  data = {}\n",
    "  data['id'] = line.name\n",
    "  data['text'] = line.values[0]\n",
    "  \n",
    "  # Save the dictionary into a temporary .json file\n",
    "  with open('/content/drive/My Drive/Models Running/Summarization/pytextrank/dat/temp.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "    \n",
    "  \n",
    "  # Stage 1 - Perform statistical parsing/tagging on a document in JSON format\n",
    "  path_stage0 = '/content/drive/My Drive/Models Running/Summarization/pytextrank/dat/temp.json'\n",
    "  path_stage1 = '/content/drive/My Drive/Models Running/Summarization/pytextrank/dat/pytextranko1.json'\n",
    "  \n",
    "  with open(path_stage1, 'w') as f:\n",
    "    for graf in ptr.parse_doc(ptr.json_iter(path_stage0)):\n",
    "        f.write(\"%s\\n\" % ptr.pretty_print(graf._asdict()))\n",
    "        \n",
    "  \n",
    "  # Stage 2 - Collect and normalize the key phrases from a parsed document \n",
    "  path_stage2 = '/content/drive/My Drive/Models Running/Summarization/pytextrank/dat/pytextranko2.json'\n",
    "\n",
    "  graph, ranks = ptr.text_rank(path_stage1)\n",
    "  ptr.render_ranks(graph, ranks)\n",
    "\n",
    "  with open(path_stage2, 'w') as f:\n",
    "      for rl in ptr.normalize_key_phrases(path_stage1, ranks):\n",
    "          f.write(\"%s\\n\" % ptr.pretty_print(rl._asdict()))\n",
    "\n",
    "#   nx.draw(graph, with_labels=True)  \n",
    "#   plt.show()\n",
    "\n",
    "  \n",
    "  # Stage 3 - Calculate a significance weight for each sentence, using MinHash to approximate a Jaccard distance from key phrases determined by TextRank\n",
    "  path_stage3 = '/content/drive/My Drive/Models Running/Summarization/pytextrank/dat/pytextranko3.json'\n",
    "\n",
    "  kernel = ptr.rank_kernel(path_stage2)\n",
    "\n",
    "  with open(path_stage3, 'w') as f:\n",
    "      for s in ptr.top_sentences(kernel, path_stage1):\n",
    "          f.write(ptr.pretty_print(s._asdict()))\n",
    "          f.write(\"\\n\")\n",
    "\n",
    "          \n",
    "  # Stage 4 - Summarize a document based on most significant sentences and key phrases\n",
    "  phrases = \", \".join(set([p for p in ptr.limit_keyphrases(path_stage2)]))\n",
    "  sent_iter = sorted(ptr.limit_sentences(path_stage3, word_limit=150), key=lambda x: x[1])\n",
    "  s = []\n",
    "\n",
    "  for sent_text, idx in sent_iter:\n",
    "      s.append(ptr.make_sentence(sent_text))\n",
    "\n",
    "  graf_text = \" \".join(s)\n",
    "  \n",
    "  return graf_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2HJXQ8cKVybP",
    "outputId": "90164d67-80f2-47df-a593-140bc73b8949"
   },
   "outputs": [],
   "source": [
    "print(\"Starting with Genre...\\n\\n\")\n",
    "genre_textrank = genre.apply( lambda line: create_summary(line), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE0fbqClh0HH"
   },
   "outputs": [],
   "source": [
    "genre_textrank = genre_textrank[genre_textrank.str.len() >= 200]\n",
    "\n",
    "genre_textrank.to_csv('/content/drive/My Drive/Models Running/Summarization/datasets/text_rank/genre.tsv', sep='\\t', header=False, index_label=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TextRank.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
